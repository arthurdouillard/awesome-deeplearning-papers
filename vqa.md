# Visual Question Answering (VQA) & Captioning

### 2017:

- [X] **MUTAN: Multimodal Tucker Fusion for Visual Question Answering**, Ben-younes et al. [`arxiv`](https://arxiv.org/abs/1705.06676)


### 2016:

- [X] **Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding**, Fukui et al. [`arxiv`](https://arxiv.org/abs/1606.01847) :star:
- [X] **DualNet: Domain-Invariant Network for Visual Question Answering**, Saito et al. [`arxiv`](https://arxiv.org/abs/1606.06108)

### 2015:

- [X] **Stacked Attention Networks for Image Question Answering**, Yang et al. [`arxiv`](https://arxiv.org/abs/1511.02274) :star:
- [X] **VQA: Visual Question Answering**, Agrawal et al. [`arxiv`](https://arxiv.org/abs/1505.00468)

### 2014:

- [X] **Show and Tell: A Neural Image Caption Generator**, Vinyals et al.
[`arxiv`](https://arxiv.org/abs/1411.4555) :star:


# Datasets

- **VQA: Visual Question Answering** [`url`](http://visualqa.org/)
  - Real images and cartoon.
